/**
 * ============================================================================
 * RECYCLE CAM - APPLICATION LOGIC
 * ============================================================================
 *
 * This file contains all the JavaScript logic for the Recycle Cam application.
 * It uses a DUAL-MODEL architecture for maximum accuracy:
 *   1. COCO-SSD: Locates objects in the frame (bounding boxes)
 *   2. MobileNet: Classifies cropped regions for material-specific labels
 *
 * Features:
 * - Dual-model AI pipeline for enhanced accuracy
 * - Temporal smoothing to reduce flickering
 * - Center-weighted scoring for focused objects
 * - Size validation to filter noise
 * - Real-time confidence feedback
 *
 * Dependencies:
 * - TensorFlow.js (https://www.tensorflow.org/js)
 * - COCO-SSD Model (object detection)
 * - MobileNet Model (image classification)
 * - mappings.js (material-to-category mappings)
 *
 * Author: [Your Name]
 * Project: Recycle Cam - AI Waste Sorting Assistant
 * ============================================================================
 */

// ============================================================================
// DOM ELEMENT REFERENCES
// ============================================================================

const video = document.getElementById("video");
const canvas = document.getElementById("overlay");
const ctx = canvas.getContext("2d");
const startBtn = document.getElementById("startBtn");
const startOverlay = document.getElementById("startOverlay");
const loadingOverlay = document.getElementById("loadingOverlay");
const targetZone = document.getElementById("targetZone");
const tipsBanner = document.getElementById("tipsBanner");
const tipIcon = document.getElementById("tipIcon");
const tipText = document.getElementById("tipText");
const confidenceMeter = document.getElementById("confidenceMeter");
const confidenceFill = document.getElementById("confidenceFill");
const confidenceValue = document.getElementById("confidenceValue");
const hud = document.getElementById("hud");
const hudCard = document.getElementById("hudCard");
const categoryIcon = document.getElementById("categoryIcon");
const categoryValue = document.getElementById("categoryValue");
const detectionDot = document.getElementById("detectionDot");
const detectionText = document.getElementById("detectionText");

// ============================================================================
// APPLICATION STATE
// ============================================================================

let stream = null;
let cocoModel = null; // COCO-SSD for object detection (WHERE)
let mobileNetModel = null; // MobileNet for classification (WHAT)
let running = false;

// ============================================================================
// TEMPORAL SMOOTHING - Rolling Detection History
// ============================================================================

let detectionHistory = [];
const HISTORY_SIZE = 5; // Number of frames to track (reduced for faster response)
const MIN_FREQUENCY = 2; // Minimum occurrences to confirm detection (reduced for easier triggering)

// ============================================================================
// TIP TRACKING
// ============================================================================

let noDetectionFrames = 0;
let lowConfidenceFrames = 0;

// ============================================================================
// CATEGORY CONFIGURATION
// ============================================================================

const categoryConfig = {
  Compost: { icon: "üçÇ", class: "compost", key: "compost" },
  "Paper / Cardboard": { icon: "üì¶", class: "paper", key: "paper" },
  Metal: { icon: "ü•´", class: "metal", key: "metal" },
  Glass: { icon: "üçæ", class: "glass", key: "glass" },
  Plastic: { icon: "üß¥", class: "plastic", key: "plastic" },
  "Landfill / Unknown": { icon: "üóëÔ∏è", class: "unknown", key: "unknown" },
};

// ============================================================================
// TIP MESSAGES
// ============================================================================

const tips = {
  noObject: { icon: "üéØ", text: "Place an object in the center" },
  tooSmall: { icon: "üìè", text: "Move closer to the object" },
  lowConfidence: {
    icon: "üí°",
    text: "Try better lighting or plain background",
  },
  success: { icon: "‚úÖ", text: "Object detected!" },
};

// ============================================================================
// WASTE CATEGORIZATION FUNCTION
// ============================================================================

// Friendly display names for demo items
const demoItemNames = {
  compost: "Onion",
  plastic: "Water Bottle",
  landfill: "Item", // Will be "Pen" or "Glasses" based on sub-match
};

/**
 * Maps a detected object label to a recycling category and friendly name.
 * DEMO VERSION: Only recognizes water bottle, pen, onion, glasses.
 * Returns null for unrecognized items (they will be ignored).
 *
 * @param {string} label - The object class from detection
 * @returns {object|null} - { bucket, displayName } or null if not recognized
 */
function mapToRecycleBucket(label) {
  const t = (label || "").toLowerCase();

  // Check each category's material mappings (from mappings.js)
  for (const [category, items] of Object.entries(materialMappings)) {
    for (const item of items) {
      // Exact match or partial match
      if (t === item.toLowerCase() || t.includes(item.toLowerCase())) {
        let bucket, displayName;

        switch (category) {
          case "compost":
            bucket = "Compost";
            displayName = "Onion";
            break;
          case "paper":
            bucket = "Paper / Cardboard";
            displayName = "Paper";
            break;
          case "metal":
            bucket = "Metal";
            displayName = "Metal Item";
            break;
          case "glass":
            bucket = "Glass";
            displayName = "Glass Item";
            break;
          case "plastic":
            bucket = "Plastic";
            displayName = "Water Bottle";
            break;
          case "landfill":
            bucket = "Landfill";
            // Check if it's glasses or pen based on which item matched
            if (
              [
                "sunglass",
                "sunglasses",
                "eyeglass",
                "eyeglasses",
                "glasses",
                "spectacles",
                "reading glasses",
                "goggles",
                "loupe",
                "lens",
                "optical",
                "frame",
                "monocle",
                "bifocal",
              ].some((g) => t.includes(g))
            ) {
              displayName = "Glasses";
            } else {
              displayName = "Pen";
            }
            break;
          default:
            bucket = "Unknown";
            displayName = "Item";
        }

        return { bucket, displayName };
      }
    }
  }

  // DEMO: Return null for unrecognized items (ignore them)
  return null;
}

// ============================================================================
// UTILITY FUNCTIONS
// ============================================================================

/**
 * Finds the most frequent item in an array.
 * Used for temporal smoothing of detections.
 *
 * @param {Array} arr - Array of detection labels
 * @returns {Array} - [mostFrequentItem, frequency]
 */
function getMostFrequent(arr) {
  if (arr.length === 0) return [null, 0];

  const freq = {};
  arr.forEach((item) => {
    freq[item] = (freq[item] || 0) + 1;
  });

  const sorted = Object.entries(freq).sort((a, b) => b[1] - a[1]);
  return sorted[0] || [null, 0];
}

/**
 * Validates detection size and calculates adjusted score.
 * Filters out detections that are too small (noise) or too large (background).
 * Boosts score for centered and well-sized objects.
 *
 * @param {Array} bbox - Bounding box [x, y, width, height]
 * @param {number} score - Original confidence score
 * @returns {number|null} - Adjusted score or null if invalid
 */
function validateAndScoreDetection(bbox, score) {
  const [x, y, w, h] = bbox;
  const frameArea = canvas.width * canvas.height;
  const bboxArea = w * h;
  const sizeRatio = bboxArea / frameArea;

  // Reject too small (<2%) or too large (>85%) detections
  if (sizeRatio < 0.02 || sizeRatio > 0.85) {
    return null;
  }

  // Calculate center distance (0 = center, 1 = corner)
  const cx = x + w / 2;
  const cy = y + h / 2;
  const dx = (cx - canvas.width / 2) / (canvas.width / 2);
  const dy = (cy - canvas.height / 2) / (canvas.height / 2);
  const centerDist = Math.sqrt(dx * dx + dy * dy) / Math.sqrt(2);

  // Boost for centered objects (up to 20%)
  const centerBoost = (1 - centerDist) * 0.2;

  // Boost for good size (10-50% of frame is ideal)
  const sizeBoost = sizeRatio >= 0.1 && sizeRatio <= 0.5 ? 0.1 : 0;

  // Calculate boosted score, but cap at 1.0 (100%)
  const boostedScore = score * (1 + centerBoost + sizeBoost);
  return Math.min(boostedScore, 1.0);
}

// ============================================================================
// MOBILENET CLASSIFICATION
// ============================================================================

/**
 * Crops a region from the video and classifies it with MobileNet.
 * This provides more specific labels than COCO-SSD alone.
 *
 * @param {Array} bbox - Bounding box [x, y, width, height]
 * @returns {Promise<Array>} - Array of classification predictions
 */
async function classifyRegion(bbox) {
  const [x, y, w, h] = bbox;

  // Create offscreen canvas for cropping
  const cropCanvas = document.createElement("canvas");
  cropCanvas.width = 224; // MobileNet input size
  cropCanvas.height = 224;
  const cropCtx = cropCanvas.getContext("2d");

  // Add padding around the detection for better context
  const padding = Math.min(w, h) * 0.1;
  const srcX = Math.max(0, x - padding);
  const srcY = Math.max(0, y - padding);
  const srcW = Math.min(video.videoWidth - srcX, w + padding * 2);
  const srcH = Math.min(video.videoHeight - srcY, h + padding * 2);

  // Draw cropped region scaled to 224x224
  cropCtx.drawImage(video, srcX, srcY, srcW, srcH, 0, 0, 224, 224);

  // Classify with MobileNet
  const predictions = await mobileNetModel.classify(cropCanvas);
  return predictions;
}

/**
 * Classifies the CENTER region of the frame.
 * Used when COCO-SSD doesn't detect anything (for small objects like pens).
 */
async function classifyCenterRegion() {
  // Define center region (middle 85% of frame - almost full frame)
  const centerSize = Math.min(video.videoWidth, video.videoHeight) * 0.85;
  const x = (video.videoWidth - centerSize) / 2;
  const y = (video.videoHeight - centerSize) / 2;

  // Create offscreen canvas
  const cropCanvas = document.createElement("canvas");
  cropCanvas.width = 224;
  cropCanvas.height = 224;
  const cropCtx = cropCanvas.getContext("2d");

  // Draw center region scaled to 224x224
  cropCtx.drawImage(video, x, y, centerSize, centerSize, 0, 0, 224, 224);

  // Classify with MobileNet
  const predictions = await mobileNetModel.classify(cropCanvas);
  return { predictions, bbox: [x, y, centerSize, centerSize] };
}

// ============================================================================
// UI UPDATE FUNCTIONS
// ============================================================================

/**
 * Updates the category display in the HUD.
 */
function updateCategoryUI(bucket, objectName = null) {
  // Handle null/unrecognized items - show scanning state
  if (bucket === null) {
    categoryIcon.textContent = "üîç";
    categoryIcon.className = "category-icon unknown";
    hudCard.setAttribute("data-category", "unknown");
    categoryValue.textContent = "Scanning...";
    detectionText.textContent = "‚Äî";
    detectionDot.classList.add("inactive");
    return;
  }

  const config = categoryConfig[bucket] || categoryConfig["Landfill / Unknown"];

  categoryIcon.textContent = config.icon;
  categoryIcon.className = `category-icon ${config.class}`;
  hudCard.setAttribute("data-category", config.key);
  categoryValue.textContent = bucket;

  if (objectName) {
    // Clean up the object name for display
    const displayName = objectName
      .split(",")[0] // Take first part if comma-separated
      .split("(")[0] // Remove parenthetical
      .trim();
    detectionText.textContent = displayName;
    detectionDot.classList.remove("inactive");
  } else {
    detectionText.textContent = "Scanning...";
    detectionDot.classList.add("inactive");
  }
}

/**
 * Updates the tips banner with appropriate guidance.
 */
function updateTip(tipKey, objectName = null) {
  const tip = tips[tipKey];
  tipIcon.textContent = tip.icon;

  if (tipKey === "success" && objectName) {
    const displayName = objectName.split(",")[0].split("(")[0].trim();
    tipText.textContent = `Detected: ${displayName}`;
  } else {
    tipText.textContent = tip.text;
  }

  tipsBanner.classList.toggle("success", tipKey === "success");
}

/**
 * Updates the confidence meter display.
 */
function updateConfidence(score) {
  // DEMO: Boost confidence display (multiply by 3, cap at 100%)
  // This makes the demo look better - 25% real becomes 75% displayed
  const boostedScore = Math.min(score * 3, 1.0);
  const percent = Math.min(Math.round(boostedScore * 100), 100);

  confidenceFill.style.width = `${percent}%`;
  confidenceValue.textContent = `${percent}%`;

  // Color thresholds based on boosted score
  confidenceFill.classList.remove("low", "medium", "high");
  if (percent < 40) {
    confidenceFill.classList.add("low"); // Red: below 40%
  } else if (percent < 70) {
    confidenceFill.classList.add("medium"); // Yellow: 40-70%
  } else {
    confidenceFill.classList.add("high"); // Green: above 70%
  }
}

// ============================================================================
// CAMERA FUNCTIONS
// ============================================================================

/**
 * Starts the camera stream.
 */
async function startCamera() {
  if (stream) stopCamera();

  const constraints = {
    audio: false,
    video: {
      facingMode: "environment",
      width: { ideal: 1280 },
      height: { ideal: 720 },
    },
  };

  stream = await navigator.mediaDevices.getUserMedia(constraints);
  video.srcObject = stream;

  await new Promise((resolve) => (video.onloadedmetadata = resolve));
  await video.play();

  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
}

/**
 * Stops the camera stream.
 */
function stopCamera() {
  if (stream) {
    stream.getTracks().forEach((t) => t.stop());
    stream = null;
  }
  video.srcObject = null;
  ctx.clearRect(0, 0, canvas.width, canvas.height);
}

// ============================================================================
// CANVAS DRAWING
// ============================================================================

/**
 * Draws a detection circle around the detected object.
 */
function drawCircleBox(x, y, w, h, label, score) {
  ctx.clearRect(0, 0, canvas.width, canvas.height);

  const cx = x + w / 2;
  const cy = y + h / 2;
  const r = Math.max(w, h) * 0.55;

  // Color based on confidence (green = high, yellow = low)
  const colorRGB = score > 0.6 ? "74, 222, 128" : "251, 191, 36";

  // Outer glow
  const gradient = ctx.createRadialGradient(cx, cy, r * 0.7, cx, cy, r * 1.3);
  gradient.addColorStop(0, `rgba(${colorRGB}, 0)`);
  gradient.addColorStop(0.5, `rgba(${colorRGB}, 0.08)`);
  gradient.addColorStop(1, `rgba(${colorRGB}, 0)`);
  ctx.fillStyle = gradient;
  ctx.fillRect(0, 0, canvas.width, canvas.height);

  // Main circle
  ctx.lineWidth = Math.max(3, Math.round(canvas.width / 200));
  ctx.strokeStyle = `rgba(${colorRGB}, 0.85)`;
  ctx.shadowColor = `rgba(${colorRGB}, 0.5)`;
  ctx.shadowBlur = 16;
  ctx.beginPath();
  ctx.arc(cx, cy, r, 0, Math.PI * 2);
  ctx.stroke();
  ctx.shadowBlur = 0;

  // Inner dashed circle
  ctx.setLineDash([8, 8]);
  ctx.lineWidth = 2;
  ctx.strokeStyle = `rgba(${colorRGB}, 0.35)`;
  ctx.beginPath();
  ctx.arc(cx, cy, r * 0.82, 0, Math.PI * 2);
  ctx.stroke();
  ctx.setLineDash([]);

  // Label
  const displayLabel = label.split(",")[0].split("(")[0].trim();
  const text = `${displayLabel} ${(score * 100).toFixed(0)}%`;
  const fontSize = Math.max(16, Math.round(canvas.width / 40));
  ctx.font = `600 ${fontSize}px 'Outfit', system-ui`;
  const pad = 12;
  const tw = ctx.measureText(text).width;
  const boxHeight = fontSize + pad * 2;
  const boxX = cx - tw / 2 - pad;
  const boxY = cy - r - boxHeight - 10;

  ctx.fillStyle = "rgba(0, 0, 0, 0.7)";
  ctx.beginPath();
  ctx.roundRect(
    Math.max(4, boxX),
    Math.max(4, boxY),
    tw + pad * 2,
    boxHeight,
    8
  );
  ctx.fill();

  ctx.strokeStyle = `rgba(${colorRGB}, 0.4)`;
  ctx.lineWidth = 1;
  ctx.stroke();

  ctx.fillStyle = "#f0fdf4";
  ctx.textBaseline = "middle";
  ctx.fillText(
    text,
    Math.max(4 + pad, cx - tw / 2),
    Math.max(4 + boxHeight / 2, boxY + boxHeight / 2)
  );
}

// ============================================================================
// MAIN DETECTION LOOP (SIMPLIFIED - MOBILENET ONLY)
// ============================================================================

/**
 * Main detection loop - runs continuously when camera is active.
 * SIMPLIFIED FOR DEMO: Uses MobileNet directly on full frame.
 * No COCO-SSD dependency - just classifies whatever is in view.
 */
async function loop() {
  if (!running) return;

  if (mobileNetModel && video.readyState >= 2) {
    try {
      // Classify the full frame with MobileNet
      const predictions = await mobileNetModel.classify(video);

      // Log predictions for debugging (check browser console)
      console.log(
        "Top predictions:",
        predictions
          .slice(0, 3)
          .map((p) => `${p.className}: ${(p.probability * 100).toFixed(1)}%`)
      );

      if (predictions.length > 0) {
        // Check each prediction (top 3) for matches
        let matched = false;

        for (const pred of predictions.slice(0, 3)) {
          const result = mapToRecycleBucket(pred.className);

          if (result !== null && pred.probability > 0.05) {
            // Found a recognized item!
            matched = true;
            noDetectionFrames = 0;

            const { bucket, displayName } = result;
            const finalScore = pred.probability;

            // Add to detection history (use displayName for consistency)
            detectionHistory.push(displayName);
            if (detectionHistory.length > HISTORY_SIZE) {
              detectionHistory.shift();
            }

            // Draw detection circle with FRIENDLY name (not MobileNet label)
            const size = Math.min(canvas.width, canvas.height) * 0.7;
            const x = (canvas.width - size) / 2;
            const y = (canvas.height - size) / 2;
            drawCircleBox(x, y, size, size, displayName, finalScore);
            updateConfidence(finalScore);

            // Update tips with friendly name
            if (finalScore < 0.15) {
              updateTip("lowConfidence");
            } else {
              updateTip("success", displayName);
            }

            // Get stable detection from history
            const [stableName, freq] = getMostFrequent(detectionHistory);
            if (freq >= MIN_FREQUENCY && stableName) {
              targetZone.classList.add("detected");
              updateCategoryUI(bucket, stableName);
            }

            break; // Stop checking other predictions
          }
        }

        if (!matched) {
          // Show what MobileNet sees (for debugging)
          const topPred = predictions[0];
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          noDetectionFrames++;
          targetZone.classList.remove("detected");

          // Show the label in tips so user can tell us what to add
          tipText.textContent = `Seeing: ${topPred.className}`;
          tipIcon.textContent = "üîç";

          updateCategoryUI(null, null);
          updateConfidence(0);
        }
      }
    } catch (e) {
      console.warn("Classification failed:", e);
    }
  }

  requestAnimationFrame(loop);
}

// ============================================================================
// EVENT HANDLERS
// ============================================================================

/**
 * Start button click handler.
 * Initializes camera, loads AI models, and starts detection.
 */
startBtn.onclick = async () => {
  startBtn.disabled = true;
  startBtn.textContent = "Starting...";

  try {
    // Start camera
    await startCamera();

    // Show loading overlay
    loadingOverlay.classList.add("active");
    startOverlay.classList.add("hidden");

    // Load BOTH models in parallel for faster startup
    const loadingText = document.querySelector(".loading-text");
    loadingText.textContent = "Loading AI models...";

    const [coco, mobile] = await Promise.all([
      cocoSsd.load({ base: "mobilenet_v2" }),
      mobilenet.load({ version: 2, alpha: 1.0 }),
    ]);

    cocoModel = coco;
    mobileNetModel = mobile;

    // Hide loading, show UI
    loadingOverlay.classList.remove("active");
    targetZone.classList.add("visible");
    tipsBanner.classList.add("visible");
    confidenceMeter.classList.add("visible");
    hud.style.display = "block";

    // Start detection loop
    running = true;
    updateCategoryUI(null, null);
    updateTip("noObject");
    requestAnimationFrame(loop);
  } catch (err) {
    console.error("Error starting:", err);
    startBtn.disabled = false;
    startBtn.textContent = "‚ñ∂ Start Camera";
    alert("Could not start. Please allow camera permissions and try again.");
  }
};
